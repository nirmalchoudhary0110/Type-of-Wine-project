# üç∑ Type of Wine Detection

This project predicts whether a wine is **Red** or **White** based on its physicochemical characteristics.  
It uses **data cleaning, visualization, and classification techniques** to explore and model the Wine Quality dataset.

---

## üìå Overview

Wine type detection is a common machine learning problem that helps in understanding how chemical properties influence wine classification.  
This notebook focuses on:
- Cleaning and preparing raw wine data
- Performing exploratory data analysis (EDA)
- Detecting and handling outliers
- Building a model to classify wine type

---

## üß† Dataset

The dataset used is **`winequalityN.csv`**, which includes features like:

| Feature | Description |
|----------|-------------|
| fixed acidity | Acidity level of the wine |
| volatile acidity | Volatile acid content |
| citric acid | Citric acid concentration |
| residual sugar | Amount of sugar left after fermentation |
| chlorides | Salt content |
| free sulfur dioxide | Free SO‚ÇÇ concentration |
| total sulfur dioxide | Total SO‚ÇÇ concentration |
| density | Density of the wine |
| pH | Acidity level |
| sulphates | Sulphate content |
| alcohol | Alcohol percentage |
| type | Red (1) or White (0) |

---

## ‚öôÔ∏è Technologies Used

- **Python 3**
- **Pandas**, **NumPy** ‚Äì Data handling  
- **Matplotlib**, **Seaborn** ‚Äì Data visualization  
- **Scikit-learn** ‚Äì Model training and evaluation  
- **Jupyter Notebook** ‚Äì Development environment

---

## üîç Exploratory Data Analysis (EDA)

The following analyses were performed:
- **Boxplots** for outlier detection  
- **Scatter plots** for feature relationships  
- **Heatmap** for feature correlation  
- **IQR method** to identify outliers  

Key insights:
- Alcohol and sulphates show strong correlation with wine type  
- Outliers were detected mainly in alcohol and residual sugar columns  
- White wines are more frequent in the dataset than red wines  

---

## üß© Model Training

Multiple classification algorithms were applied, including:
- Logistic Regression  
- Decision Tree (before and after parameter tuning)  
- Random Forest  
- Naive Bayes  
- Support Vector Machine (SVM)  
- K-Nearest Neighbors (KNN)

Each model‚Äôs accuracy score is compared below.

---

## üìà Results

- **Best performing models:** Logistic Regression, Random Forest, and SVM  
- **Highest accuracy:** 98%  
- Demonstrates clear separation between red and white wines based on features.

![Model Accuracy Comparison](WhatsApp%20Image%202025-10-23%20at%204.34.39%20PM.jpeg)
